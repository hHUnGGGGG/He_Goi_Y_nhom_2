{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 14432210,
     "sourceType": "datasetVersion",
     "datasetId": 9218233
    },
    {
     "sourceId": 14437161,
     "sourceType": "datasetVersion",
     "datasetId": 9221754
    }
   ],
   "dockerImageVersionId": 31193,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": "import os\n\nmind_data_path = \"/kaggle/input/mind-data/mind_data\"  \nos.makedirs(mind_data_path, exist_ok=True) ",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-09T03:30:17.319979Z",
     "iopub.execute_input": "2026-01-09T03:30:17.320287Z",
     "iopub.status.idle": "2026-01-09T03:30:17.330060Z",
     "shell.execute_reply.started": "2026-01-09T03:30:17.320253Z",
     "shell.execute_reply": "2026-01-09T03:30:17.329375Z"
    }
   },
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": "!pip install tensorflow==2.15.0 \"numpy<2.0\"",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-09T03:30:17.330830Z",
     "iopub.execute_input": "2026-01-09T03:30:17.331022Z",
     "iopub.status.idle": "2026-01-09T03:30:53.213213Z",
     "shell.execute_reply.started": "2026-01-09T03:30:17.331006Z",
     "shell.execute_reply": "2026-01-09T03:30:53.212280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Collecting tensorflow==2.15.0\n  Using cached tensorflow-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\nCollecting numpy<2.0\n  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n\u001B[2K     \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m61.0/61.0 kB\u001B[0m \u001B[31m2.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (25.2.10)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (3.14.0)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (18.1.1)\nRequirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.2.0)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (3.4.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (25.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (4.25.8)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (75.2.0)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.17.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (3.1.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (4.15.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.14.2)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.37.1)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.74.0)\nCollecting tensorboard<2.16,>=2.15 (from tensorflow==2.15.0)\n  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\nCollecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow==2.15.0)\n  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\nCollecting keras<2.16,>=2.15.0 (from tensorflow==2.15.0)\n  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.15.0) (0.45.1)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.38.0)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.0.0)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.8.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.32.5)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.1.3)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (5.5.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (4.9.1)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.0.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2025.10.5)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.0.3)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.6.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.3.1)\nDownloading tensorflow-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.3 MB)\n\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m475.3/475.3 MB\u001B[0m \u001B[31m4.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m:00:01\u001B[0m00:01\u001B[0m\n\u001B[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m18.3/18.3 MB\u001B[0m \u001B[31m104.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n\u001B[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m1.7/1.7 MB\u001B[0m \u001B[31m72.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m5.5/5.5 MB\u001B[0m \u001B[31m87.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0mta \u001B[36m0:00:01\u001B[0m\n\u001B[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m442.0/442.0 kB\u001B[0m \u001B[31m27.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hInstalling collected packages: tensorflow-estimator, numpy, keras, tensorboard, tensorflow\n  Attempting uninstall: tensorflow-estimator\n    Found existing installation: tensorflow-estimator 2.14.0\n    Uninstalling tensorflow-estimator-2.14.0:\n      Successfully uninstalled tensorflow-estimator-2.14.0\n  Attempting uninstall: numpy\n    Found existing installation: numpy 2.0.2\n    Uninstalling numpy-2.0.2:\n      Successfully uninstalled numpy-2.0.2\n  Attempting uninstall: keras\n    Found existing installation: keras 2.14.0\n    Uninstalling keras-2.14.0:\n      Successfully uninstalled keras-2.14.0\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.14.1\n    Uninstalling tensorboard-2.14.1:\n      Successfully uninstalled tensorboard-2.14.1\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.14.0\n    Uninstalling tensorflow-2.14.0:\n      Successfully uninstalled tensorflow-2.14.0\n\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncornac 2.3.5 requires numpy>2.0.0, but you have numpy 1.26.4 which is incompatible.\ndatasets 4.4.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 7.5.1 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\ngoogle-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\njax 0.5.2 requires ml_dtypes>=0.4.0, but you have ml-dtypes 0.2.0 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\nopencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\nopencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\nimbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\nydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\ntf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.15.0 which is incompatible.\ntensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.15.0 which is incompatible.\ntensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.15.0 which is incompatible.\ntensorstore 0.1.74 requires ml_dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\nopencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\numap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001B[0m\u001B[31m\n\u001B[0mSuccessfully installed keras-2.15.0 numpy-1.26.4 tensorboard-2.15.2 tensorflow-2.15.0 tensorflow-estimator-2.15.0\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": "# CÃ i cuDNN 8.9 tá»« pip\n!pip uninstall tensorflow -y\n!pip install nvidia-cudnn-cu12==8.9.7.29\n!pip install tensorflow==2.15.0\n\n# Thiáº¿t láº­p LD_LIBRARY_PATH\nimport os\ncudnn_path = '/usr/local/lib/python3.11/dist-packages/nvidia/cudnn/lib'\nos.environ['LD_LIBRARY_PATH'] = f\"{cudnn_path}:{os.environ.get('LD_LIBRARY_PATH', '')}\"\n\nprint(\"âœ… cuDNN 8.9 installed. Please RESTART KERNEL!\")",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-09T03:30:53.215015Z",
     "iopub.execute_input": "2026-01-09T03:30:53.215280Z",
     "iopub.status.idle": "2026-01-09T03:31:42.141863Z",
     "shell.execute_reply.started": "2026-01-09T03:30:53.215256Z",
     "shell.execute_reply": "2026-01-09T03:31:42.141150Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Found existing installation: tensorflow 2.15.0\nUninstalling tensorflow-2.15.0:\n  Successfully uninstalled tensorflow-2.15.0\nCollecting nvidia-cudnn-cu12==8.9.7.29\n  Downloading nvidia_cudnn_cu12-8.9.7.29-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cublas-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cudnn-cu12==8.9.7.29) (12.4.5.8)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cudnn-cu12==8.9.7.29) (12.4.127)\nDownloading nvidia_cudnn_cu12-8.9.7.29-py3-none-manylinux1_x86_64.whl (704.7 MB)\n\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m704.7/704.7 MB\u001B[0m \u001B[31m2.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m:00:01\u001B[0m00:01\u001B[0m\n\u001B[?25hInstalling collected packages: nvidia-cudnn-cu12\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntorch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 8.9.7.29 which is incompatible.\u001B[0m\u001B[31m\n\u001B[0mSuccessfully installed nvidia-cudnn-cu12-8.9.7.29\nCollecting tensorflow==2.15.0\n  Using cached tensorflow-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (25.2.10)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (3.14.0)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (18.1.1)\nRequirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.2.0)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.26.4)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (3.4.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (25.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (4.25.8)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (75.2.0)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.17.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (3.1.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (4.15.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.14.2)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.37.1)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.74.0)\nRequirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (2.15.2)\nRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (2.15.0)\nRequirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (2.15.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.15.0) (0.45.1)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.38.0)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.0.0)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.8.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.32.5)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.1.3)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (5.5.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (4.9.1)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.0.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2025.10.5)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.0.3)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.6.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.3.1)\nUsing cached tensorflow-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.3 MB)\nInstalling collected packages: tensorflow\n\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\ntf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.15.0 which is incompatible.\ntensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.15.0 which is incompatible.\ntensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.15.0 which is incompatible.\u001B[0m\u001B[31m\n\u001B[0mSuccessfully installed tensorflow-2.15.0\nâœ… cuDNN 8.9 installed. Please RESTART KERNEL!\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": "import os\ncudnn_path = '/usr/local/lib/python3.11/dist-packages/nvidia/cudnn/lib'\nos.environ['LD_LIBRARY_PATH'] = f\"{cudnn_path}:{os.environ.get('LD_LIBRARY_PATH', '')}\"\n\nimport tensorflow as tf\nprint(\"GPUs:\", tf.config.list_physical_devices('GPU'))",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-09T03:31:42.142839Z",
     "iopub.execute_input": "2026-01-09T03:31:42.143082Z",
     "iopub.status.idle": "2026-01-09T03:31:50.325888Z",
     "shell.execute_reply.started": "2026-01-09T03:31:42.143057Z",
     "shell.execute_reply": "2026-01-09T03:31:50.325210Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": "2026-01-09 03:31:42.498223: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2026-01-09 03:31:42.498290: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2026-01-09 03:31:42.499742: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": "# Cell 1: Monkey patch Ä‘á»ƒ force embedding lÃªn GPU\nimport os\nos.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n\nimport tensorflow as tf\n\n# Monkey patch Embedding layer Ä‘á»ƒ force GPU placement\noriginal_embedding_init = tf.keras.layers.Embedding.__init__\n\ndef patched_embedding_init(self, *args, **kwargs):\n    # Force embeddings on GPU\n    with tf.device('/GPU:0'):\n        original_embedding_init(self, *args, **kwargs)\n\ntf.keras.layers.Embedding.__init__ = patched_embedding_init\n\nprint(\"âœ… Patched Embedding layer to use GPU\")",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-09T03:31:50.326660Z",
     "iopub.execute_input": "2026-01-09T03:31:50.327144Z",
     "iopub.status.idle": "2026-01-09T03:31:50.350287Z",
     "shell.execute_reply.started": "2026-01-09T03:31:50.327124Z",
     "shell.execute_reply": "2026-01-09T03:31:50.349614Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "âœ… Patched Embedding layer to use GPU\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": "# Cell 2: Setup  \nfrom recommenders.models.newsrec.newsrec_utils import prepare_hparams    \nfrom recommenders.models.newsrec.models.naml import NAMLModel  # Thay Ä‘á»•i  \nfrom recommenders.models.newsrec.io.mind_all_iterator import MINDAllIterator  # Thay Ä‘á»•i  \n  \ntrain_news_file = os.path.join(mind_data_path, \"train\", \"news.tsv\")    \ntrain_behaviors_file = os.path.join(mind_data_path, \"train\", \"behaviors.tsv\")    \nvalid_news_file = os.path.join(mind_data_path, \"valid\", \"news.tsv\")    \nvalid_behaviors_file = os.path.join(mind_data_path, \"valid\", \"behaviors.tsv\")    \nwordEmb_file = os.path.join(mind_data_path, \"utils\", \"embedding_all.npy\")  # Thay Ä‘á»•i  \nuserDict_file = os.path.join(mind_data_path, \"utils\", \"uid2index.pkl\")    \nwordDict_file = os.path.join(mind_data_path, \"utils\", \"word_dict_all.pkl\")  # Thay Ä‘á»•i  \nvertDict_file = os.path.join(mind_data_path, \"utils\", \"vert_dict.pkl\")  # ThÃªm  \nsubvertDict_file = os.path.join(mind_data_path, \"utils\", \"subvert_dict.pkl\")  # ThÃªm  \nyaml_file = os.path.join(mind_data_path, \"utils\", \"naml.yaml\")  # Thay Ä‘á»•i  \n  \nhparams = prepare_hparams(    \n    yaml_file,    \n    wordEmb_file=wordEmb_file,    \n    wordDict_file=wordDict_file,    \n    userDict_file=userDict_file,  \n    vertDict_file=vertDict_file,  # ThÃªm  \n    subvertDict_file=subvertDict_file,  # ThÃªm  \n    epochs=1,  \n    batch_size=384  \n)    \n  \n# Create model with GPU  \nwith tf.device('/GPU:0'):  \n    iterator = MINDAllIterator  # Thay Ä‘á»•i  \n    model = NAMLModel(hparams, iterator, seed=42)  # Thay Ä‘á»•i  \n  \nprint(\"âœ… NAML Model created on GPU\")",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-09T03:31:50.350938Z",
     "iopub.execute_input": "2026-01-09T03:31:50.351122Z",
     "iopub.status.idle": "2026-01-09T03:31:56.302527Z",
     "shell.execute_reply.started": "2026-01-09T03:31:50.351108Z",
     "shell.execute_reply": "2026-01-09T03:31:56.301707Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "âœ… NAML Model created on GPU\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/legacy/adam.py:118: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n  super().__init__(name, **kwargs)\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": "# Cell 3: Load checkpoint\n# checkpoint_path = \"/kaggle/input/model-epoch-10-13/model/nrms_ckpt\"\n# model.model.load_weights(checkpoint_path)\n# print(f\"âœ… Checkpoint loaded\")",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Cell 3: Load checkpoint\ncheckpoint_path = \"/kaggle/input/model-naml/model/nrms_ckpt\"\nmodel.model.load_weights(checkpoint_path)\nprint(f\"âœ… Checkpoint loaded\")",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-09T03:31:56.303519Z",
     "iopub.execute_input": "2026-01-09T03:31:56.303769Z",
     "iopub.status.idle": "2026-01-09T03:31:57.735591Z",
     "shell.execute_reply.started": "2026-01-09T03:31:56.303752Z",
     "shell.execute_reply": "2026-01-09T03:31:57.734953Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "âœ… Checkpoint loaded\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": "# Cell 4: Training\nprint(\"ğŸ”¥ Starting training...\")\nmodel.fit(  \n    train_news_file,\n    train_behaviors_file,\n    valid_news_file,\n    valid_behaviors_file\n)\nprint(\"âœ… Training completed!\")",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-08T03:42:15.645464Z",
     "iopub.execute_input": "2026-01-08T03:42:15.646311Z",
     "iopub.status.idle": "2026-01-08T03:45:06.664561Z",
     "shell.execute_reply.started": "2026-01-08T03:42:15.646284Z",
     "shell.execute_reply": "2026-01-08T03:45:06.663468Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# ÄÃ¡nh giÃ¡ trÃªn validation set  \neval_results = model.run_eval(valid_news_file, valid_behaviors_file)  \nprint(\"Káº¿t quáº£ Ä‘Ã¡nh giÃ¡:\")  \nfor metric, value in eval_results.items():  \n    print(f\"{metric}: {value:.4f}\")",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-08T03:26:36.572547Z",
     "iopub.status.idle": "2026-01-08T03:26:36.572974Z",
     "shell.execute_reply.started": "2026-01-08T03:26:36.572862Z",
     "shell.execute_reply": "2026-01-08T03:26:36.572873Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "model_path = os.path.join(\"/kaggle/working/\", \"model\")\nos.makedirs(model_path, exist_ok=True)\n\nmodel.model.save_weights(os.path.join(model_path, \"nrms_ckpt\"))",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-08T03:26:36.573527Z",
     "iopub.status.idle": "2026-01-08T03:26:36.573760Z",
     "shell.execute_reply.started": "2026-01-08T03:26:36.573641Z",
     "shell.execute_reply": "2026-01-08T03:26:36.573654Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "from tqdm import tqdm\nimport numpy as np\n\ntest_behaviors_file = \"/kaggle/input/mind-data/mind_data/test/behaviors.tsv\"  \ntest_news_file = \"/kaggle/input/mind-data/mind_data/test/news.tsv\"\n\nprint(\"ğŸ”§ Patching iterator for test set (no labels)...\")\n\n# Backup original method\noriginal_init = model.test_iterator.init_behaviors\n\ndef init_behaviors_no_labels(behaviors_file):\n    \"\"\"Modified init_behaviors for test set without labels\"\"\"\n    model.test_iterator.histories = []\n    model.test_iterator.imprs = []\n    model.test_iterator.labels = []\n    model.test_iterator.impr_indexes = []\n    model.test_iterator.uindexes = []\n\n    with open(behaviors_file, \"r\", encoding=\"utf-8\") as rd:\n        impr_index = 0\n        for line in rd:\n            uid, time, history, impr = line.strip(\"\\n\").split(\"\\t\")[-4:]\n\n            # Parse history\n            history = [model.test_iterator.nid2index[i] for i in history.split() if i in model.test_iterator.nid2index]\n            history = [0] * (model.test_iterator.his_size - len(history)) + history[:model.test_iterator.his_size]\n\n            # Parse impressions - TEST SET KHÃ”NG CÃ“ LABEL\n            impr_news = []\n            for item in impr.split():\n                # Test set: chá»‰ cÃ³ news_id, KHÃ”NG cÃ³ \"-0\" hay \"-1\"\n                if \"-\" in item:\n                    # Validation/train set format: N12345-1\n                    news_id = item.split(\"-\")[0]\n                else:\n                    # Test set format: N12345\n                    news_id = item\n                \n                if news_id in model.test_iterator.nid2index:\n                    impr_news.append(model.test_iterator.nid2index[news_id])\n            \n            # Táº¡o dummy labels (khÃ´ng dÃ¹ng cho test)\n            label = [0] * len(impr_news)\n            \n            uindex = model.test_iterator.uid2index[uid] if uid in model.test_iterator.uid2index else 0\n\n            model.test_iterator.histories.append(history)\n            model.test_iterator.imprs.append(impr_news)\n            model.test_iterator.labels.append(label)\n            model.test_iterator.impr_indexes.append(impr_index)\n            model.test_iterator.uindexes.append(uindex)\n            impr_index += 1\n\n# Apply patch\nmodel.test_iterator.init_behaviors = init_behaviors_no_labels\n\nprint(\"âœ… Iterator patched for test set\")\n\n# Run evaluationa\nprint(\"\\nğŸ” Running evaluation on test set...\")\nprint(\"   Model will use trained weights to generate rankings\")\n\ngroup_impr_indexes, group_labels, group_preds = model.run_fast_eval(\n    test_news_file, test_behaviors_file\n)\n\nprint(f\"\\nâœ… Generated predictions for {len(group_impr_indexes)} impressions\")\n\n# Write predictions\nprint(\"\\nğŸ’¾ Writing predictions to file...\")\nprediction_file = \"/kaggle/working/prediction.txt\"\n\nwith open(prediction_file, 'w') as f:  \n    for impr_index, preds in tqdm(zip(group_impr_indexes, group_preds), \n                                   total=len(group_impr_indexes),\n                                   desc=\"Writing\"):  \n        # MIND competition format: impression_id báº¯t Ä‘áº§u tá»« 1\n        impr_id = impr_index + 1\n        \n        # Calculate rankings (score cao nháº¥t = rank 1)\n        pred_rank = (np.argsort(np.argsort(preds)[::-1]) + 1).tolist()  \n        pred_rank_str = '[' + ','.join([str(i) for i in pred_rank]) + ']'  \n        \n        f.write(f\"{impr_id} {pred_rank_str}\\n\")\n\nprint(f\"\\nâœ… Prediction file saved to: {prediction_file}\")\n\n# Validate output\nprint(\"\\nğŸ” Validating output format...\")\nwith open(prediction_file, 'r') as f:\n    lines = f.readlines()\n    print(f\"   Total predictions: {len(lines)}\")\n    print(f\"   First 3 lines:\")\n    for i in range(min(3, len(lines))):\n        parts = lines[i].strip().split()\n        print(f\"      ImprID={parts[0]}, Rankings={parts[1][:50]}{'...' if len(parts[1]) > 50 else ''}\")\n\nprint(\"\\nâœ… File ready to submit to MIND competition!\")\nprint(f\"   Download: {prediction_file}\")",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-09T03:31:57.736348Z",
     "iopub.execute_input": "2026-01-09T03:31:57.736648Z",
     "iopub.status.idle": "2026-01-09T05:00:48.572122Z",
     "shell.execute_reply.started": "2026-01-09T03:31:57.736630Z",
     "shell.execute_reply": "2026-01-09T05:00:48.571194Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "ğŸ”§ Patching iterator for test set (no labels)...\nâœ… Iterator patched for test set\n\nğŸ” Running evaluation on test set...\n   Model will use trained weights to generate rankings\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "0it [00:00, ?it/s]/usr/local/lib/python3.11/dist-packages/keras/src/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n  updates=self.state_updates,\n120579it [03:45, 535.73it/s]\n2370344it [1:22:00, 481.73it/s]\n2370727it [02:34, 15326.04it/s]\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "\nâœ… Generated predictions for 2370727 impressions\n\nğŸ’¾ Writing predictions to file...\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Writing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2370727/2370727 [00:29<00:00, 80174.95it/s]\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "\nâœ… Prediction file saved to: /kaggle/working/prediction.txt\n\nğŸ” Validating output format...\n   Total predictions: 2370727\n   First 3 lines:\n      ImprID=1, Rankings=[7,8,14,4,6,11,16,15,3,1,12,10,2,5,13,9]\n      ImprID=2, Rankings=[6,3,5,2,4,7,1]\n      ImprID=3, Rankings=[72,71,1,11,8,81,52,45,6,62,17,21,56,7,22,46,79,73...\n\nâœ… File ready to submit to MIND competition!\n   Download: /kaggle/working/prediction.txt\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": "import zipfile\nimport os\n\n# ÄÆ°á»ng dáº«n file input (Ä‘Ã£ táº¡o á»Ÿ bÆ°á»›c trÆ°á»›c) vÃ  output\nsource_file = \"/kaggle/working/prediction.txt\"\nzip_output_path = \"/kaggle/working/prediction.zip\"\n\n\ntry:\n    # Táº¡o file zip vá»›i cháº¿ Ä‘á»™ nÃ©n ZIP_DEFLATED\n    with zipfile.ZipFile(zip_output_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n        # arcname='prediction.txt' Ä‘áº£m báº£o file trong zip chá»‰ cÃ³ tÃªn lÃ  prediction.txt\n        # chá»© khÃ´ng chá»©a Ä‘Æ°á»ng dáº«n thÆ° má»¥c máº¹ (/kaggle/working/...)\n        zipf.write(source_file, arcname='prediction.txt')\n\n\n    # (TÃ¹y chá»n) Kiá»ƒm tra ná»™i dung bÃªn trong file zip vá»«a táº¡o\n    with zipfile.ZipFile(zip_output_path, 'r') as zipf:\n        for info in zipf.infolist():\n            print(f\"File: {info.filename} | Size: {info.file_size / 1024:.2f} KB\")\n\nexcept Exception as e:\n    print(e)",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
